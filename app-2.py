
import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import random

st.set_page_config(page_title="Veille DS Automobiles", layout="wide")
st.title("üöó Agent de Veille ‚Äì DS Automobiles (100% gratuit)")

# Scraping Bing News
def scrape_bing_news(query, max_results=10):
    url = f"https://www.bing.com/news/search?q={query}&setlang=fr"
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(url, headers=headers)
    soup = BeautifulSoup(r.text, "html.parser")
    articles = []
    for item in soup.select("div.news-card")[:max_results]:
        try:
            title = item.select_one("a.title").text.strip()
            link = item.select_one("a.title")['href']
            snippet = item.select_one("div.snippet").text.strip()
            source = item.select_one("div.source").text.strip()
            articles.append({
                'date': datetime.today().date(),
                'titre': title,
                'contenu': snippet,
                'source': source,
                'lien': link
            })
        except:
            continue
    return pd.DataFrame(articles)

# D√©tection de mod√®le
MODELES_DS = ["DS N4", "DS N8", "DS7", "DS3", "DS9", "DS4"]

def detecter_modele(titre):
    for m in MODELES_DS:
        if m.lower() in titre.lower():
            return m
    return "DS Global"

# Analyse "IA" minimale sans mod√®le lourd
def analyser_article(row):
    r√©sum√© = row['contenu'][:200] + "..."  # R√©sum√© simplifi√©
    ton = "Positif" if any(w in row['contenu'].lower() for w in ["succ√®s", "innovant", "record"]) else "Neutre"
    modele = detecter_modele(row['titre'])
    return pd.Series({'r√©sum√©': r√©sum√©, 'ton': ton, 'mod√®le': modele})

# Interface utilisateur
nb_articles = st.slider("Nombre d'articles √† r√©cup√©rer", 5, 30, 10)

if st.button("üîç Lancer la veille maintenant"):
    articles = scrape_bing_news("DS Automobiles", nb_articles)
    if not articles.empty:
        with st.spinner("Analyse des articles en cours..."):
            articles[['r√©sum√©', 'ton', 'mod√®le']] = articles.apply(analyser_article, axis=1)

        # Calcul notori√©t√©
        mentions_today = len(articles)
        moyenne_7j = 25 / 7
        indice = int((mentions_today / max(moyenne_7j, 1)) * 50 + random.randint(0, 20))
        niveau = 'üî¥ Pic' if indice > 75 else 'üü° Stable' if indice > 50 else 'üü¢ Faible'

        st.metric("Indice de notori√©t√©", f"{indice}/100", niveau)
        st.dataframe(articles[['date', 'titre', 'mod√®le', 'ton', 'r√©sum√©', 'source', 'lien']])
    else:
        st.warning("Aucun article trouv√©. Veuillez r√©essayer plus tard.")
